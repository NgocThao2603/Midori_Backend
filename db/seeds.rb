require 'csv'
require 'json'

# # X√≥a d·ªØ li·ªáu c≈©
# Chapter.destroy_all
# Lesson.destroy_all
# Vocabulary.destroy_all
# Meaning.destroy_all
# Example.destroy_all

# ƒê·ªãnh nghƒ©a danh s√°ch chapters
chapters_data = [
  # N2 chapters
  { title: "Unit 01 - ÂêçË©ûA", level: "N2", range: (1..100) },
  { title: "Unit 02 - ÂãïË©ûA", level: "N2", range: (101..220) },
  { title: "Unit 03 - ÂΩ¢ÂÆπË©ûA", level: "N2", range: (221..270) },
  { title: "Unit 04 - ÂêçË©ûB", level: "N2", range: (271..370) },
  { title: "„Åæ„Å®„ÇÅÔºë - Ë§áÂêàÂãïË©û", level: "N2", range: (371..460) },
  { title: "Unit 05 - „Ç´„Çø„Ç´„ÉäA", level: "N2", range: (461..510) },
  { title: "Unit 06 - ÂâØË©ûÔºãÊé•Á∂öË©û", level: "N2", range: (511..580) },
  { title: "Unit 07 - ÂêçË©ûC", level: "N2", range: (581..655) },
  { title: "„Åæ„Å®„ÇÅ2 - Âêå„ÅòÊº¢Â≠ó„ÇíÂê´„ÇÄÂêçË©û", level: "N2", range: (656..680) },
  { title: "Unit 08 - ÂãïË©ûB", level: "N2", range: (681..790) },
  { title: "Unit 09 - „Ç´„Çø„Ç´„ÉäB", level: "N2", range: (791..840) },
  { title: "Unit 10 - ÂΩ¢ÂÆπË©ûB", level: "N2", range: (841..890) },
  { title: "Unit 11 - ÂêçË©ûD", level: "N2", range: (891..990) },
  { title: "Unit 12 - ÂãïË©ûC", level: "N2", range: (991..1090) },
  { title: "Unit 13 - ÂâØË©ûÔºãÈÄ£‰ΩìË©û", level: "N2", range: (1091..1160) },

  # N3 chapters
  { title: "Unit 01 - ÂêçË©ûA", level: "N3", range: (1..120) },
  { title: "Unit 02 - ÂãïË©ûA", level: "N3", range: (121..220) },
  { title: "„Åæ„Å®„ÇÅ - ÈÄ£Áî®ÂêçË©û", level: "N3", range: (221..258) },
  { title: "Unit 03 - ÂΩ¢ÂÆπË©ûA", level: "N3", range: (259..298) },
  { title: "„Åæ„Å®„ÇÅ - „Ç§ÂΩ¢ÂÆπË©ûÔºã„Åæ„ÇãÔºè„ÇÅ„Çã", level: "N3", range: (299..310) },
  { title: "Unit 04 - ÂêçË©ûB", level: "N3", range: (311..410) },
  { title: "Unit 05 - ÂãïË©ûB", level: "N3", range: (411..510) },
  { title: "Unit 06 - „Ç´„Çø„Ç´„ÉäA", level: "N3", range: (511..550) },
  { title: "Unit 07 - ÂΩ¢ÂÆπË©ûB", level: "N3", range: (551..590) },
  { title: "Unit 08 - ÂâØË©ûA ", level: "N3", range: (591..635) },
  { title: "Unit 09 - ÂêçË©ûC", level: "N3", range: (636..715) },
  { title: "Unit 10 - ÂãïË©ûC", level: "N3", range: (716..795) },
  { title: "Unit 11 - „Ç´„Çø„Ç´„ÉäB", level: "N3", range: (796..835) },
  { title: "„Åæ„Å®„ÇÅ - ÊñôÁêÜ„ÅÆÂãïË©û", level: "N3", range: (836..845) },
  { title: "Unit 12 - ÂâØË©ûB„ÄÅÈÄ£‰ΩìË©û„ÉªÊé•Á∂öË©û", level: "N3", range: (846..880) },

  # N1 chapters
  { title: "Unit 01 - ÂêçË©ûA", level: "N1", range: (1..100) },
  { title: "Unit 02 - ÂãïË©ûA", level: "N1", range: (101..190) },
  { title: "Unit 03 - ÂΩ¢ÂÆπË©ûA", level: "N1", range: (191..280) },
  { title: "Unit 04 - ÂêçË©ûB", level: "N1", range: (281..380) },
  { title: "Unit 05 - Ë§áÂêàÂãïË©û", level: "N1", range: (381..480) },
  { title: "Unit 06 - „Ç´„Çø„Ç´„ÉäA", level: "N1", range: (481..530) },
  { title: "Unit 07 - ÂâØË©ûAÔºãÊé•Á∂öË©û", level: "N1", range: (531..600) },
  { title: "Unit 08 - ÂêçË©ûC", level: "N1", range: (601..700) },
  { title: "Unit 09 - ÂãïË©ûB", level: "N1", range: (701..800) },
  { title: "Unit 10 - „Ç´„Çø„Ç´„ÉäB", level: "N1", range: (801..850) },
  { title: "Unit 11 - ÂΩ¢ÂÆπË©ûB", level: "N1", range: (851..930) },
  { title: "Unit 12 - ÂêçË©ûD", level: "N1", range: (931..1020) },
  { title: "Unit 13 - ÂãïË©ûC", level: "N1", range: (1021..1110) },
  { title: "Unit 14 - ÂâØË©ûBÔºãÈÄ£‰ΩìË©û", level: "N1", range: (1111..1170) }
]

# ƒê·ªçc d·ªØ li·ªáu CSV
csv_path = Rails.root.join('db/data/n1.csv')
csv_data = CSV.read(csv_path, headers: true)

def create_phrase_with_translation(phrase_text, vocabulary, prefix, suffix, phrase_type)
  # D·ªãch phrase sang ti·∫øng Vi·ªát
  translated_meaning = HandleData::TranslationService.translate_to_vietnamese(phrase_text)
  furigana = HandleData::FuriganaService.generate_furigana(phrase_text)
  
  # T·∫°o phrase
  vocabulary.phrases.create!(
    phrase: phrase_text,
    main_word: vocabulary.kanji,
    prefix: prefix,
    suffix: suffix,
    meaning: translated_meaning,
    furigana: furigana,
    phrase_type: phrase_type
  )
  
  puts "  üìù Phrase: #{phrase_text} -> #{translated_meaning}"
  
  # Th√™m delay nh·ªè ƒë·ªÉ tr√°nh rate limit
  sleep(0.2)
end

# T·∫°o d·ªØ li·ªáu
chapters_data.each do |data|
  chapter = Chapter.find_or_initialize_by(title: data[:title], level: data[:level])
  chapter.save! unless chapter.persisted?

  vocab_count = data[:range].size
  lesson_size = case chapter.title
  # N2
  when "Unit 07 - ÂêçË©ûC" then 7
  when "„Åæ„Å®„ÇÅ2 - Âêå„ÅòÊº¢Â≠ó„ÇíÂê´„ÇÄÂêçË©û" then (vocab_count.to_f / 15).ceil

  # N3
  when "„Åæ„Å®„ÇÅ - „Ç§ÂΩ¢ÂÆπË©ûÔºã„Åæ„ÇãÔºè„ÇÅ„Çã" then 1
  when "Unit 12 - ÂâØË©ûB„ÄÅÈÄ£‰ΩìË©û„ÉªÊé•Á∂öË©û" then 3
  when "Unit 08 - ÂâØË©ûA" then (vocab_count.to_f / 15).ceil

  # N1
  else (vocab_count.to_f / 10).ceil
  end

  words_per_lesson = (vocab_count.to_f / lesson_size).ceil
  vocab_ids = data[:range].to_a

  vocab_ids.each_slice(words_per_lesson).with_index(1) do |lesson_vocab, index|
    lesson = chapter.lessons.find_or_initialize_by(title: "B√†i #{index}")
    lesson.save! unless lesson.persisted?

    lesson_vocab.each do |vocab_id|
      row = csv_data.find { |r| r["stt"].to_i == vocab_id }
      next unless row

      # X√°c ƒë·ªãnh word_type d·ª±a v√†o title c·ªßa chapter
      word_type =
        if chapter.title.include?("ÂêçË©û")
          "Danh t·ª´"
        elsif chapter.title.include?(" ÂãïË©û")
          "ƒê·ªông t·ª´"
        elsif chapter.title.include?("ÂΩ¢ÂÆπË©û")
          "T√≠nh t·ª´"
        elsif chapter.title.include?("Ë§áÂêàÂãïË©û")
          "ƒê·ªông t·ª´ gh√©p"
        elsif chapter.title.include?("„Ç´„Çø„Ç´„Éä")
          "Katakana"
        elsif chapter.title.include?("ÂâØË©ûB„ÄÅÈÄ£‰ΩìË©û„ÉªÊé•Á∂öË©û")
          "Ph√≥ t·ª´/ Li√™n (th·ªÉ ) t·ª´"
        elsif [ "ÂâØË©ûÔºãÊé•Á∂öË©û", "ÔºãÊé•Á∂öË©û" ].any? { |phrase| chapter.title.include?(phrase) }
          "Ph√≥ t·ª´/ Li√™n t·ª´"
        elsif [ "ÂâØË©ûÔºãÈÄ£‰ΩìË©û", "ÔºãÈÄ£‰ΩìË©û" ].any? { |phrase| chapter.title.include?(phrase) }
          "Ph√≥ t·ª´/ Li√™n th·ªÉ t·ª´"
        elsif chapter.title.include?("ÂâØË©û")
          "Ph√≥ t·ª´"
        else
          "Kh√°c"
        end

      PHRASE_TYPES = [ "Èñ¢", "È°û", "Âêà", "ÈÄ£", "ÂØæ", "Âêç", "ÊÖ£" ]

      # T·∫°o t·ª´ v·ª±ng
      # vocabulary = lesson.vocabularies.create!(
      #   stt: row["stt"].to_i,
      #   kanji: row["word"],
      #   hanviet: row["Sino-Vietnamese"],
      #   kana: row["furigana"],
      #   word_type: word_type
      # )

      vocabulary = lesson.vocabularies.find_or_initialize_by(stt: row["stt"].to_i)
      vocabulary.assign_attributes(
        kanji: row["word"],
        hanviet: row["Sino-Vietnamese"],
        kana: row["furigana"],
        word_type: word_type
      )
      vocabulary.save!

      # X·ª≠ l√Ω nhi·ªÅu nghƒ©a
      meanings = row["meaning"].to_s.split(',').map(&:strip)
      meanings.each do |meaning|
        unless vocabulary.meanings.exists?(meaning: meaning)
          vocabulary.meanings.create!(meaning: meaning)
        end
      end

      # T·∫°o v√≠ d·ª•
      def safe_parse_json(json_str)
        begin
          # N·∫øu d·ªØ li·ªáu l√† d·∫°ng m·∫£ng Ruby, chuy·ªÉn th√†nh chu·ªói JSON
          unless json_str.strip.start_with?('[') && json_str.strip.end_with?(']')
            raise JSON::ParserError, "Kh√¥ng ph·∫£i ƒë·ªãnh d·∫°ng JSON"
          end

          # Chu·∫©n h√≥a d·∫•u nh√°y cong th√†nh nh√°y th·∫≥ng
          json_str = json_str.tr("""", '"')

          # Chu·∫©n h√≥a d·∫•u nh√°y ƒë∆°n n·∫øu c√≥
          json_str = json_str.gsub("'", '"')

          # Parse JSON
          JSON.parse(json_str)
        rescue JSON::ParserError => e
          puts "JSON l·ªói: #{json_str}, l·ªói: #{e.message}"
          []
        end
      end

      # X·ª≠ l√Ω d·ªØ li·ªáu example
      examples_data = row["example"].present? ? safe_parse_json(row["example"]) : []
      valid_examples = examples_data.select do |example_pair|
        example_pair.is_a?(Array) && example_pair.size == 2 &&
        !example_pair[0].start_with?("Èñ¢ ", "È°û ", "Âêà ", "ÈÄ£ ", "ÂØæ ", "Âêç ", "ÊÖ£ ") &&
        !example_pair[0].include?("Ôºø") &&
        example_pair[1].is_a?(String) && !example_pair[1].strip.empty?
      end

      # valid_examples.each do |example_pair|
      #   clean_jp = example_pair[0].sub(/^\d+\.\s*/, "")

      #   example = vocabulary.examples.create!(
      #     example_sentence: clean_jp,
      #     meaning_sentence: example_pair[1]
      #   )

      #   tokens = HandleData::TokenizerService.tokenize(example.example_sentence)
      #   tokens.each do |token|
      #     next if token[:surface].blank?
      #     ExampleToken.create!(
      #       example_id: example.id,
      #       token_index: token[:index],
      #       jp_token: token[:surface],
      #       vn_token: HandleData::TranslationService.translate_to_vietnamese(token[:surface])
      #     )
      #   end
      # end

      valid_examples.each do |example_pair|
        clean_jp = example_pair[0].sub(/^\d+\.\s*/, "")
        meaning_jp = example_pair[1]

        example = vocabulary.examples.find_or_initialize_by(example_sentence: clean_jp)
        example.meaning_sentence = meaning_jp
        example.save!

        unless example.example_tokens.exists?
          tokens = HandleData::TokenizerService.tokenize(example.example_sentence)
          tokens.each do |token|
            next if token[:surface].blank?

            example.example_tokens.create!(
              token_index: token[:index],
              jp_token: token[:surface],
              vn_token: HandleData::TranslationService.translate_to_vietnamese(token[:surface])
            )
          end
        end
      end

      # X·ª≠ l√Ω phrases - PH∆Ø∆†NG PH√ÅP M·ªöI
      def process_phrases(examples_data, vocabulary)
        phrases_data = examples_data.select { |pair| 
          pair.is_a?(Array) && pair.size == 2 &&
          PHRASE_TYPES.any? { |type| pair[0].start_with?("#{type} ") }
        }
        
        phrases_data.each do |phrase_pair|
          raw_phrase = phrase_pair[0]
          phrase_meaning = phrase_pair[1].presence || ""

          # T√°ch phrase_type
          detected_type = nil
          PHRASE_TYPES.each do |type|
            if raw_phrase.start_with?("#{type} ")
              detected_type = type
              raw_phrase = raw_phrase.sub("#{type} ", "")
              break
            end
          end

          process_by_type(raw_phrase, phrase_meaning, detected_type, vocabulary)
        end
      end

      def process_by_type(raw_phrase, phrase_meaning, phrase_type, vocabulary)
        case phrase_type
        when "Èñ¢", "È°û", "ÂØæ"
          # Simple pattern - ch·ªâ t√°ch b·∫±ng d·∫•u ph·∫©y
          process_simple_pattern(raw_phrase, phrase_meaning, phrase_type, vocabulary)
        when "Âêà", "ÈÄ£"
          # Complex pattern - c√≥ th·ªÉ c√≥ Ôºø, <=> v√† ngo·∫∑c ƒë∆°n
          process_complex_pattern(raw_phrase, phrase_meaning, phrase_type, vocabulary)
        end
      end

      def process_simple_pattern(raw_phrase, phrase_meaning, phrase_type, vocabulary)
        # T√°ch b·∫±ng d·∫•u ph·∫©y (c·∫£ , v√† „ÄÅ)
        phrases = raw_phrase.split(/[,„ÄÅ]/).map(&:strip)
        
        phrases.each do |phrase|
          next if phrase.empty?
          
          create_phrase_with_translation(
            phrase,
            vocabulary,
            nil,
            nil,
            phrase_type
          )
        end
      end

      def process_complex_pattern(raw_phrase, phrase_meaning, phrase_type, vocabulary)
        # X·ª≠ l√Ω pattern c√≥ ngo·∫∑c ƒë∆°n tr∆∞·ªõc
        if raw_phrase.include?("Ôºà") && raw_phrase.include?("Ôºâ")
          process_parentheses_pattern(raw_phrase, phrase_meaning, phrase_type, vocabulary)
        else
          # T√°ch b·∫±ng d·∫•u ph·∫©y (c·∫£ , v√† „ÄÅ) tr∆∞·ªõc
          phrase_parts = raw_phrase.split(/[,„ÄÅ]/).map(&:strip)
          
          phrase_parts.each do |phrase_part|
            next if phrase_part.empty?
            
            if phrase_part =~ /ÔºúÔºùÔºû|<=>/ || phrase_part.include?("„Éª")
              process_contrast_phrase(phrase_part, phrase_meaning, phrase_type, vocabulary)
            elsif phrase_part.include?("Ôºø")
              process_underscore_phrase(phrase_part, phrase_meaning, phrase_type, vocabulary)
            else
              # Kh√¥ng c√≥ Ôºø - x·ª≠ l√Ω nh∆∞ simple pattern
              create_phrase_with_translation(
                phrase_part,
                vocabulary,
                nil,
                nil,
                phrase_type
              )
            end
          end
        end
      end

      def process_parentheses_pattern(raw_phrase, phrase_meaning, phrase_type, vocabulary)
        # X·ª≠ l√Ω pattern c√≥ ngo·∫∑c ƒë∆°n - VD: "ÔºøÂ≠êÔºàÈÅ∫‰ºùÂ≠êÊìç‰Ωú„ÄÅÈÅ∫‰ºùÂ≠êÊ≤ªÁôÇ„ÄÅÈÅ∫‰ºùÂ≠êÁµÑ„ÅøÊèõ„ÅàÔºâ"
        
        # T√°ch ph·∫ßn tr∆∞·ªõc v√† trong ngo·∫∑c
        paren_start = raw_phrase.index("Ôºà")
        paren_end = raw_phrase.index("Ôºâ")
        
        if paren_start && paren_end && paren_start < paren_end
          base_part = raw_phrase[0...paren_start].strip
          inside_paren = raw_phrase[(paren_start + 1)...paren_end].strip
          
          # T·∫°o phrase cho ph·∫ßn base
          if base_part.include?("Ôºø")
            parts = base_part.split("Ôºø")
            prefix = parts[0].presence
            suffix = parts[1].presence
            
            phrase_text = [prefix, vocabulary.kanji, suffix].compact.join
            create_phrase_with_translation(
              phrase_text,
              vocabulary,
              prefix,
              suffix,
              phrase_type
            )
          end
          
          # X·ª≠ l√Ω ph·∫ßn trong ngo·∫∑c - t√°ch b·∫±ng d·∫•u ph·∫©y
          inside_parts = inside_paren.split(/[,„ÄÅ]/).map(&:strip)
          inside_parts.each do |part|
            next if part.empty?
            
            create_phrase_with_translation(
              part,
              vocabulary,
              nil,
              nil,
              phrase_type
            )
          end
        end
      end

      def process_contrast_phrase(phrase_part, phrase_meaning, phrase_type, vocabulary)
        # X·ª≠ l√Ω pattern c√≥ <=> ho·∫∑c „Éª
        if phrase_part.include?("Ôºø")
          if phrase_part =~ /ÔºúÔºùÔºû|<=>/
            # C√≥ Ôºø v√† <=> 
            contrast_parts = phrase_part.split(/ÔºúÔºùÔºû|<=>/).map(&:strip)
            
            if contrast_parts.length == 2
              first_part = contrast_parts[0]
              second_part = contrast_parts[1]
              
              # Case 1: Ôºø ·ªü ƒë·∫ßu ph·∫ßn ƒë·∫ßu - VD: "Ôºø„ÅåÊó©„ÅÑÔºúÔºùÔºûÈÅÖ„ÅÑ"
              if first_part.start_with?("Ôºø") && !second_part.include?("Ôºø")
                parts = first_part.split("Ôºø")
                prefix = parts[0].presence
                first_suffix = parts[1].presence
                
                # T·∫°o phrase ƒë·∫ßu ti√™n
                if first_suffix
                  phrase1 = [prefix, vocabulary.kanji, first_suffix].compact.join
                  create_phrase_with_translation(
                    phrase1,
                    vocabulary,
                    prefix,
                    first_suffix,
                    phrase_type
                  )
                end
                
                # X·ª≠ l√Ω ph·∫ßn sau <=>
                connector = extract_connector_from_suffix(first_suffix)
                second_suffix = connector ? "#{connector}#{second_part}" : second_part
                
                phrase2 = [prefix, vocabulary.kanji, second_suffix].compact.join
                create_phrase_with_translation(
                  phrase2,
                  vocabulary,
                  prefix,
                  second_suffix,
                  phrase_type
                )
              else
                # Case 2: C·∫£ hai ph·∫ßn ƒë·ªÅu c√≥ Ôºø ho·∫∑c pattern ph·ª©c t·∫°p
                # VD: "Â•ΩÔºøÔºúÔºùÔºû‰∏çÔºø" ho·∫∑c "Ôºø„ÅåË±ä„Å†ÔºúÔºùÔºûÔºø„Å´‰πè„Åó„ÅÑ"
                [first_part, second_part].each do |part|
                  if part.include?("Ôºø")
                    parts = part.split("Ôºø")
                    prefix = parts[0].presence
                    suffix = parts[1].presence
                    
                    phrase_text = [prefix, vocabulary.kanji, suffix].compact.join
                    create_phrase_with_translation(
                      phrase_text,
                      vocabulary,
                      prefix,
                      suffix,
                      phrase_type
                    )
                  else
                    # Ph·∫ßn kh√¥ng c√≥ Ôºø
                    create_phrase_with_translation(
                      part,
                      vocabulary,
                      nil,
                      nil,
                      phrase_type
                    )
                  end
                end
              end
            end
          elsif phrase_part.include?("„Éª")
            # C√≥ Ôºø v√† „Éª - VD: "Ôºø„Åå‰∏ä„Åå„Çã„Éª„Çí„ÅÇ„Åí„Çã"
            dot_parts = phrase_part.split("„Éª").map(&:strip)
            
            # T√¨m ph·∫ßn c√≥ Ôºø ƒë·ªÉ l·∫•y prefix
            base_prefix = nil
            dot_parts.each do |part|
              if part.include?("Ôºø")
                parts = part.split("Ôºø")
                base_prefix = parts[0].presence
                break
              end
            end
            
            dot_parts.each do |part|
              if part.include?("Ôºø")
                # Ph·∫ßn c√≥ Ôºø - x·ª≠ l√Ω b√¨nh th∆∞·ªùng
                parts = part.split("Ôºø")
                prefix = parts[0].presence
                suffix = parts[1].presence
                
                phrase_text = [prefix, vocabulary.kanji, suffix].compact.join
                create_phrase_with_translation(
                  phrase_text,
                  vocabulary,
                  prefix,
                  suffix,
                  phrase_type
                )
              else
                # Ph·∫ßn kh√¥ng c√≥ Ôºø - th√™m t·ª´ g·ªëc v√†o
                # VD: "„Çí„ÅÇ„Åí„Çã" ‚Üí "ËÉΩÂäõ„Çí„ÅÇ„Åí„Çã"
                phrase_text = [base_prefix, vocabulary.kanji, part].compact.join
                create_phrase_with_translation(
                  phrase_text,
                  vocabulary,
                  base_prefix,
                  part,
                  phrase_type
                )
              end
            end
          else
            # Ch·ªâ c√≥ Ôºø - x·ª≠ l√Ω b√¨nh th∆∞·ªùng
            process_underscore_phrase(phrase_part, phrase_meaning, phrase_type, vocabulary)
          end
        else
          # Kh√¥ng c√≥ Ôºø
          if phrase_part =~ /ÔºúÔºùÔºû|<=>/
            # Kh√¥ng c√≥ Ôºø nh∆∞ng c√≥ <=> - VD: "Â•ΩÊ≥ÅÔºúÔºùÔºû‰∏çÊ≥Å"
            contrasts = phrase_part.split(/ÔºúÔºùÔºû|<=>/).map(&:strip)
            contrasts.each do |contrast|
              next if contrast.empty?
              create_phrase_with_translation(
                contrast,
                vocabulary,
                nil,
                nil,
                phrase_type
              )
            end
          elsif phrase_part.include?("„Éª")
            # Kh√¥ng c√≥ Ôºø nh∆∞ng c√≥ „Éª
            dot_parts = phrase_part.split("„Éª").map(&:strip)
            dot_parts.each do |part|
              next if part.empty?
              create_phrase_with_translation(
                part,
                vocabulary,
                nil,
                nil,
                phrase_type
              )
            end
          end
        end
      end

      def extract_connector_from_suffix(suffix)
        # Tr√≠ch xu·∫•t tr·ª£ t·ª´ t·ª´ ƒë·∫ßu suffix
        return nil unless suffix
        
        connectors = ["„Åå", "„Çí", "„Å´", "„Åß", "„Åã„Çâ", "„Åæ„Åß", "„Å®", "„ÇÑ", "„ÅÆ", "„ÅØ", "„ÇÇ", "„Å†„Åë", "„Å∞„Åã„Çä"]
        connectors.each do |conn|
          if suffix.start_with?(conn)
            return conn
          end
        end
        nil
      end

      def process_underscore_phrase(phrase_part, phrase_meaning, phrase_type, vocabulary)
        # X·ª≠ l√Ω pattern c√≥ Ôºø nh∆∞ng kh√¥ng c√≥ <=> ho·∫∑c „Éª
        # VD: "ÔºøÁµåÈ®ì", "Ôºø„ÇíÈÄÅ„Çã"

        parts = phrase_part.split("Ôºø")
        return unless parts.length == 2

        prefix = parts[0].presence
        suffix = parts[1].presence

        phrase_text = [ prefix, vocabulary.kanji, suffix ].compact.join

        create_phrase_with_translation(
          phrase_text,
          vocabulary,
          prefix,
          suffix,
          phrase_type
        )
      end

      # G·ªçi h√†m x·ª≠ l√Ω phrases
      process_phrases(examples_data, vocabulary)
    end
  end
end

# ==========================================================================
Lesson.find_each do |lesson|
# Lesson.joins(:chapter).where(chapters: { level: "N1" }).find_each do |lesson|
  begin
    puts "Processing Lesson ID: #{lesson.id}"

    AutoGenQuestion::MatchQuestionGeneratorService.new(lesson).call
    AutoGenQuestion::ChoiceQuestionGeneratorService.new(lesson).call
    AutoGenQuestion::SortQuestionGeneratorService.new(lesson).call
    AutoGenQuestion::FillBlankQuestionGeneratorService.new(lesson).call

    puts "Generated questions for Lesson ID: #{lesson.id}"
  rescue => e
    puts "Skipped Lesson ID: #{lesson.id} due to error: #{e.message}"
  end
end
# ==========================================================================

Lesson.find_each do |lesson|
  Test.create!(
    lesson: lesson,
    title: "B√†i test 1",
    duration_minutes: 20
  )
end

puts "Seeding completed!"
